<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Local Whisper Speech Recognition</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        button {
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
        }
        #status {
            margin: 10px 0;
            color: #666;
        }
        #transcription {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            min-height: 100px;
        }
        .segment {
            margin: 5px 0;
            padding: 5px;
            background-color: #f5f5f5;
        }
    </style>
</head>
<body>
    <h1>Local Whisper Speech Recognition</h1>
    <button id="startRecord">Start Recording</button>
    <button id="stopRecord" disabled>Stop Recording</button>
    <div id="status">Standby...</div>
    <div id="transcription"></div>

    <script>
        let mediaRecorder;
        let audioChunks = [];

        // Function to get media device with browser compatibility
        async function getMediaDevice() {
            if (navigator.mediaDevices === undefined) {
                navigator.mediaDevices = {};
            }

            // getUserMedia browser compatibility handling
            if (navigator.mediaDevices.getUserMedia === undefined) {
                navigator.mediaDevices.getUserMedia = function(constraints) {
                    const getUserMedia = navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
                    
                    if (!getUserMedia) {
                        return Promise.reject(new Error('getUserMedia is not implemented in this browser'));
                    }

                    return new Promise(function(resolve, reject) {
                        getUserMedia.call(navigator, constraints, resolve, reject);
                    });
                }
            }

            try {
                return await navigator.mediaDevices.getUserMedia({ audio: true });
            } catch (err) {
                throw new Error('Failed to access microphone: ' + err.message);
            }
        }

        // Check MediaRecorder support
        function isMediaRecorderSupported() {
            return 'MediaRecorder' in window;
        }

        document.getElementById('startRecord').addEventListener('click', async () => {
            try {
                // Check MediaRecorder support
                if (!isMediaRecorderSupported()) {
                    throw new Error('Your browser does not support MediaRecorder');
                }

                const stream = await getMediaDevice();
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.addEventListener('dataavailable', event => {
                    audioChunks.push(event.data);
                });

                mediaRecorder.addEventListener('stop', async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                    await sendToWhisper(audioBlob);
                });

                mediaRecorder.start();
                document.getElementById('status').textContent = 'Recording...';
                document.getElementById('startRecord').disabled = true;
                document.getElementById('stopRecord').disabled = false;
            } catch (error) {
                console.error('Failed to start recording:', error);
                document.getElementById('status').textContent = 'Error: ' + error.message;
            }
        });

        document.getElementById('stopRecord').addEventListener('click', () => {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                document.getElementById('status').textContent = 'Processing audio...';
                document.getElementById('startRecord').disabled = false;
                document.getElementById('stopRecord').disabled = true;
            }
        });

        async function sendToWhisper(audioBlob) {
            const formData = new FormData();
            formData.append('audio', audioBlob);

            try {
                const response = await fetch('http://localhost:5000/transcribe', {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) {
                    throw new Error('Server error: ' + response.status);
                }

                const data = await response.json();
                
                const transcriptionDiv = document.getElementById('transcription');
                transcriptionDiv.innerHTML = '<h3>Transcription Results:</h3>';
                
                data.segments.forEach(segment => {
                    const segmentDiv = document.createElement('div');
                    segmentDiv.className = 'segment';
                    segmentDiv.textContent = `${formatTime(segment.start)} - ${formatTime(segment.end)}: ${segment.text}`;
                    transcriptionDiv.appendChild(segmentDiv);
                });

                document.getElementById('status').textContent = 'Completed';
            } catch (error) {
                console.error('Server error:', error);
                document.getElementById('status').textContent = 'Error: ' + error.message;
            }
        }

        function formatTime(seconds) {
            const minutes = Math.floor(seconds / 60);
            const remainingSeconds = Math.floor(seconds % 60);
            return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
        }
    </script>
</body>
</html>